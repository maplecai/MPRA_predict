{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-09 17:22:46.654594: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-09 17:22:46.661025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733736166.668638    8944 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733736166.670927    8944 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-09 17:22:46.678986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from MPRA_predict.utils import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import functools\n",
    "\n",
    "\n",
    "def organism_path(organism):\n",
    "  return os.path.join('/home/shared/enformer_data', organism)\n",
    "\n",
    "\n",
    "def get_dataset(organism, subset, num_threads=8):\n",
    "  metadata = get_metadata(organism)\n",
    "  dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n",
    "                                    compression_type='ZLIB',\n",
    "                                    num_parallel_reads=num_threads)\n",
    "  dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n",
    "                        num_parallel_calls=num_threads)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def get_metadata(organism):\n",
    "  # Keys:\n",
    "  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
    "  # pool_width, crop_bp, target_length\n",
    "  path = os.path.join(organism_path(organism), 'statistics.json')\n",
    "  with tf.io.gfile.GFile(path, 'r') as f:\n",
    "    return json.load(f)\n",
    "\n",
    "\n",
    "def tfrecord_files(organism, subset):\n",
    "  # Sort the values by int(*).\n",
    "  return sorted(tf.io.gfile.glob(os.path.join(\n",
    "      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n",
    "  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "\n",
    "def deserialize(serialized_example, metadata):\n",
    "  \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "  feature_map = {\n",
    "      'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "      'target': tf.io.FixedLenFeature([], tf.string),\n",
    "  }\n",
    "  example = tf.io.parse_example(serialized_example, feature_map)\n",
    "  sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "  sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n",
    "  sequence = tf.cast(sequence, tf.float32)\n",
    "\n",
    "  target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "  target = tf.reshape(target,\n",
    "                      (metadata['target_length'], metadata['num_targets']))\n",
    "  target = tf.cast(target, tf.float32)\n",
    "\n",
    "  return {'sequence': sequence,\n",
    "          'target': target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 16:39:38.402043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-09 16:39:38.402054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: wanglab-server\n",
      "2024-12-09 16:39:38.402057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: wanglab-server\n",
      "2024-12-09 16:39:38.402087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.183.1\n",
      "2024-12-09 16:39:38.402094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.183.1\n",
      "2024-12-09 16:39:38.402095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.183.1\n",
      "2024-12-09 16:39:38.402218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "human_dataset = get_dataset('human', 'train').batch(1).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': (TensorShape([1, 131072, 4]), tf.float32), 'target': (TensorShape([1, 896, 5313]), tf.float32)}\n"
     ]
    }
   ],
   "source": [
    "it = iter(human_dataset)\n",
    "example = next(it)\n",
    "print({k: (v.shape, v.dtype) for k,v in example.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(organism):\n",
    "    # Keys:\n",
    "    # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
    "    # pool_width, crop_bp, target_length\n",
    "    path = os.path.join(organism_path(organism), 'statistics.json')\n",
    "    with tf.io.gfile.GFile(path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    return metadata\n",
    "\n",
    "metadata = get_metadata('human')\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_files('human', 'train'),\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=8)\n",
    "dataset = dataset.map(functools.partial(deserialize, metadata=metadata), \n",
    "                      num_parallel_calls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34021"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['train_seqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': (TensorShape([131072, 4]), tf.float32), 'target': (TensorShape([896, 5313]), tf.float32)}\n"
     ]
    }
   ],
   "source": [
    "it = iter(dataset)\n",
    "example = next(it)\n",
    "print({k: (v.shape, v.dtype) for k,v in example.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, head, max_steps=None):\n",
    "    @tf.function\n",
    "    def predict(x):\n",
    "        return model(x, is_training=False)[head]\n",
    "    \n",
    "    pred = []\n",
    "    for i, batch in tqdm(enumerate(dataset)):\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        pred.append(predict(batch['sequence']))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from enformer_pytorch import Enformer, from_pretrained\n",
    "\n",
    "from MPRA_predict.utils import *\n",
    "from MPRA_predict.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
