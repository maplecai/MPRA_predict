{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MPRA_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMPRA_predict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMPRA_predict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MPRA_predict'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from MPRA_predict.utils import *\n",
    "from MPRA_predict.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_npy_files(files_dir, files_prefix, output_file):\n",
    "    \"\"\"\n",
    "    合并多个 .npy 文件并保存为一个文件。\n",
    "\n",
    "    :param files_dir: 存放 .npy 文件的目录\n",
    "    :param files_prefix: 保存文件的前缀，比如 'Enformer_Siraj_pred_part'\n",
    "    :param output_file: 合并后保存的文件名\n",
    "    \"\"\"\n",
    "    # 找到所有符合前缀的 .npy 文件\n",
    "    file_list = sorted([f for f in os.listdir(files_dir) if f.startswith(files_prefix) and f.endswith('.npy')])\n",
    "\n",
    "    if not file_list:\n",
    "        print(\"No files found with the given prefix!\")\n",
    "        return\n",
    "\n",
    "    # 初始化一个空的列表来存放所有部分数据\n",
    "    merged_data = []\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(files_dir, file)\n",
    "        print(f'Loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        merged_data.append(data)\n",
    "\n",
    "    # 将所有部分数据拼接成一个大数组\n",
    "    merged_data = np.concatenate(merged_data, axis=0)\n",
    "\n",
    "    # 确保输出文件的完整路径\n",
    "    output_path = os.path.join(files_dir, output_file)\n",
    "\n",
    "    # 保存合并后的数据到新的 .npy 文件\n",
    "    np.save(output_path, merged_data)\n",
    "    print(f\"All files merged and saved to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "merge_npy_files('data', 'Enformer_Siraj_pred_part', 'Enformer_Siraj_pred_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18225816, 0.23097768, 0.28722847, ..., 0.03399419, 0.07661163,\n",
       "       0.14517386], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0 = np.load('data/Enformer_Siraj_pred_all_200.npy')\n",
    "f0[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1552077 , 0.18577066, 0.24951428, ..., 0.0444698 , 0.06986648,\n",
       "       0.1880454 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = np.load('data/Enformer_Siraj_pred_256.npy')\n",
    "f1[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08149792, 0.0595834 , 0.08398052, ..., 0.03100194, 0.33120534,\n",
       "       0.05567969], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = np.load('data/Enformer_Siraj_pred_196608.npy')\n",
    "f2[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15517054, 0.18572146, 0.24941607, ..., 0.04441018, 0.06986722,\n",
       "       0.18794422], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = np.load('data/Enformer_Siraj_pred_all_256.npy')\n",
    "f3[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14751925, 0.17848201, 0.25576484, ..., 0.0628978 , 0.184787  ,\n",
       "       0.30512774], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f4 = np.load('data/Enformer_Siraj_pred_512.npy')\n",
    "f4[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18457259, 0.23168151, 0.3205341 , ..., 0.0258045 , 0.0878814 ,\n",
       "       0.14335236], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f5 = np.load('data/Enformer_Siraj_pred_random_256_0.npy')\n",
    "f5[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19631377, 0.24610853, 0.36514908, ..., 0.02263626, 0.07708836,\n",
       "       0.14065497], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f6 = np.load('data/Enformer_Siraj_pred_random_256_1.npy')\n",
    "f6[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20343414, 0.2651039 , 0.3828038 , ..., 0.02811209, 0.07859381,\n",
       "       0.17197105], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f7 = np.load('data/Enformer_Siraj_pred_random_256_2.npy')\n",
    "f7[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1947735 , 0.2476313 , 0.3561623 , ..., 0.02551762, 0.08118786,\n",
       "       0.1519928 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f8 = (f5 + f6 + f7) / 3\n",
    "f8[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8965479029150073\n",
      "0.4060833421812523\n",
      "0.8965552383455654\n",
      "0.680348792250925\n",
      "0.9467930646101872\n",
      "0.9375813623946999\n",
      "0.9400493824932699\n",
      "0.9592113984231165\n"
     ]
    }
   ],
   "source": [
    "r = pearson(f0[:160].mean(1).reshape(-1), f1[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f2[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f3[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f4[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f5[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f6[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f7[:160].mean(1).reshape(-1))\n",
    "print(r)\n",
    "r = pearson(f0[:160].mean(1).reshape(-1), f8[:160].mean(1).reshape(-1))\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9114097033708313\n"
     ]
    }
   ],
   "source": [
    "r = pearson(f1[:160].mean(1).reshape(-1), f8[:160].mean(1).reshape(-1))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
