{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 23:46:43.207865: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 23:46:43.215067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733932003.222955  209374 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733932003.225299  209374 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 23:46:43.234082: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from MPRA_predict.utils import *\n",
    "from MPRA_predict.datasets import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = random_onehots(length=393216, num=100)\n",
    "# np.save('data/random_onehots_393216.npy', inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733823763.867808   27518 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:06:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 393216, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]I0000 00:00:1733823766.281756   27738 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "100%|██████████| 25/25 [00:29<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 896, 5313)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_tf = hub.load(\"enformer_tfhub\").model\n",
    "\n",
    "inputs = np.load('data/random_onehots_393216.npy')\n",
    "print(inputs.shape)\n",
    "\n",
    "inputs_tf =  tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "all_predictions = []\n",
    "for i in tqdm(range(0, len(inputs), batch_size)):\n",
    "    batch_inputs = inputs[i:i+batch_size]\n",
    "    batch_predictions = model_tf.predict_on_batch(batch_inputs)\n",
    "    all_predictions.append(batch_predictions['human'])\n",
    "\n",
    "predictions = tf.concat(all_predictions, axis=0)\n",
    "print(predictions.shape)  # [batch_size, 896, 5313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 896, 5313)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_pred = predictions.numpy()\n",
    "np.save('data/tf_pred.npy', tf_pred)\n",
    "tf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "# cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            x = x[0].to(device)\n",
    "            output = model(x)['human']\n",
    "            y_pred.append(output.cpu().numpy())\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 393216, 4)\n",
      "torch.Size([100, 196608, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = np.load('data/random_onehots_393216.npy')\n",
    "print(inputs.shape)\n",
    "\n",
    "inputs_torch = crop_onehots(inputs, 196608)\n",
    "inputs_torch = torch.tensor(inputs_torch, dtype=torch.float32)\n",
    "print(inputs_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:10<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "trained_model_path = 'Enformer'\n",
    "device = 'cuda:0'\n",
    "batch_size = 4\n",
    "\n",
    "model = from_pretrained(trained_model_path, use_tf_gamma=True)\n",
    "dataset = TensorDataset(inputs_torch)\n",
    "test_data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "torch_pred = get_pred(model, test_data_loader, device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "np.save('data/torch_pred.npy', torch_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 896, 5313) (100, 896, 5313)\n"
     ]
    }
   ],
   "source": [
    "torch_pred = np.load('data/torch_pred.npy')\n",
    "tf_pred = np.load('data/tf_pred.npy')\n",
    "print(torch_pred.shape, tf_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.9852688832251754, pvalue=0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(torch_pred.reshape(-1), tf_pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title `get_dataset(organism, subset, num_threads=8)`\n",
    "import glob\n",
    "import json\n",
    "import functools\n",
    "\n",
    "\n",
    "# @title `get_targets(organism)`\n",
    "def get_targets(organism):\n",
    "  # targets_txt = f'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_{organism}.txt'\n",
    "  targets_txt = f'/home/shared/enformer_data/{organism}/targets.txt'\n",
    "  return pd.read_csv(targets_txt, sep='\\t')\n",
    "\n",
    "\n",
    "def organism_path(organism):\n",
    "  # return os.path.join('gs://basenji_barnyard/data', organism)\n",
    "  return os.path.join('/home/shared/enformer_data', organism)\n",
    "\n",
    "\n",
    "def get_dataset(organism, subset, num_threads=8):\n",
    "  metadata = get_metadata(organism)\n",
    "  dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n",
    "                                    compression_type='ZLIB',\n",
    "                                    num_parallel_reads=num_threads)\n",
    "  dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n",
    "                        num_parallel_calls=num_threads)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def get_metadata(organism):\n",
    "  # Keys:\n",
    "  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
    "  # pool_width, crop_bp, target_length\n",
    "  path = os.path.join(organism_path(organism), 'statistics.json')\n",
    "  with tf.io.gfile.GFile(path, 'r') as f:\n",
    "    return json.load(f)\n",
    "\n",
    "\n",
    "def tfrecord_files(organism, subset):\n",
    "  # Sort the values by int(*).\n",
    "  return sorted(tf.io.gfile.glob(os.path.join(\n",
    "      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n",
    "  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "\n",
    "def deserialize(serialized_example, metadata):\n",
    "  \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "  feature_map = {\n",
    "      'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "      'target': tf.io.FixedLenFeature([], tf.string),\n",
    "  }\n",
    "  example = tf.io.parse_example(serialized_example, feature_map)\n",
    "  sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "  sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n",
    "  sequence = tf.cast(sequence, tf.float32)\n",
    "\n",
    "  target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "  target = tf.reshape(target,\n",
    "                      (metadata['target_length'], metadata['num_targets']))\n",
    "  target = tf.cast(target, tf.float32)\n",
    "\n",
    "  return {'sequence': sequence,\n",
    "          'target': target}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genome</th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF833POA</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:cerebellum male adult (27 years) and mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF110QGM</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:frontal cortex male adult (27 years) and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF880MKD</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:chorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF463ZLQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:Ishikawa treated with 0.02% dimethyl sul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF890OGQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:GM03348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  genome   identifier  \\\n",
       "0      0       0  ENCFF833POA   \n",
       "1      1       0  ENCFF110QGM   \n",
       "2      2       0  ENCFF880MKD   \n",
       "3      3       0  ENCFF463ZLQ   \n",
       "4      4       0  ENCFF890OGQ   \n",
       "\n",
       "                                                file  clip  scale sum_stat  \\\n",
       "0  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "1  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "2  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "3  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "4  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "\n",
       "                                         description  \n",
       "0  DNASE:cerebellum male adult (27 years) and mal...  \n",
       "1  DNASE:frontal cortex male adult (27 years) and...  \n",
       "2                                      DNASE:chorion  \n",
       "3  DNASE:Ishikawa treated with 0.02% dimethyl sul...  \n",
       "4                                      DNASE:GM03348  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_human = get_targets('human')\n",
    "targets_human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': (TensorShape([1, 131072, 4]), tf.float32), 'target': (TensorShape([1, 896, 5313]), tf.float32)}\n"
     ]
    }
   ],
   "source": [
    "human_dataset = get_dataset('human', 'test').batch(1).repeat()\n",
    "it = iter(human_dataset)\n",
    "example = next(it)\n",
    "print({k: (v.shape, v.dtype) for k,v in example.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集太大,没办法一次性预测所有序列\n",
    "\n",
    "human_dataset = human_dataset.batch(16)\n",
    "\n",
    "predictions = []\n",
    "for sample in human_dataset:\n",
    "    input_data = sample['sequence']\n",
    "    prediction = model.predict_on_batch(tf.expand_dims(input_data, axis=0))  # 添加 batch 维度\n",
    "    predictions.append(prediction)\n",
    "\n",
    "predictions = tf.concat(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
