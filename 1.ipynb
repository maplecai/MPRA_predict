{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained_models/enformer/pytorch_model.bin\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Enformer                                           [2, 2, 1643]              --\n",
       "├─Sequential: 1-1                                  [2, 2, 3072]              --\n",
       "│    └─Rearrange: 2-1                              [2, 4, 196608]            --\n",
       "│    └─Sequential: 2-2                             [2, 768, 98304]           --\n",
       "│    │    └─Conv1d: 3-1                            [2, 768, 196608]          46,848\n",
       "│    │    └─Residual: 3-2                          [2, 768, 196608]          592,128\n",
       "│    │    └─AttentionPool: 3-3                     [2, 768, 98304]           589,824\n",
       "│    └─Sequential: 2-3                             [2, 1536, 1536]           --\n",
       "│    │    └─Sequential: 3-4                        [2, 768, 49152]           4,133,376\n",
       "│    │    └─Sequential: 3-5                        [2, 896, 24576]           5,051,392\n",
       "│    │    └─Sequential: 3-6                        [2, 1024, 12288]          6,690,560\n",
       "│    │    └─Sequential: 3-7                        [2, 1152, 6144]           8,559,104\n",
       "│    │    └─Sequential: 3-8                        [2, 1280, 3072]           10,657,024\n",
       "│    │    └─Sequential: 3-9                        [2, 1536, 1536]           14,557,696\n",
       "│    └─Rearrange: 2-4                              [2, 1536, 1536]           --\n",
       "│    └─Sequential: 2-5                             [2, 1536, 1536]           --\n",
       "│    │    └─Sequential: 3-10                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-11                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-12                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-13                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-14                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-15                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-16                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-17                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-18                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-19                       [2, 1536, 1536]           15,840,256\n",
       "│    │    └─Sequential: 3-20                       [2, 1536, 1536]           15,840,256\n",
       "│    └─TargetLengthCrop: 2-6                       [2, 2, 1536]              --\n",
       "│    └─Sequential: 2-7                             [2, 2, 3072]              --\n",
       "│    │    └─Rearrange: 3-21                        [2, 1536, 2]              --\n",
       "│    │    └─Sequential: 3-22                       [2, 3072, 2]              4,724,736\n",
       "│    │    └─Rearrange: 3-23                        [2, 2, 3072]              --\n",
       "│    │    └─Dropout: 3-24                          [2, 2, 3072]              --\n",
       "│    │    └─GELU: 3-25                             [2, 2, 3072]              --\n",
       "├─ModuleDict: 1-2                                  --                        --\n",
       "│    └─Sequential: 2-8                             [2, 2, 5313]              --\n",
       "│    │    └─Linear: 3-26                           [2, 2, 5313]              16,326,849\n",
       "│    │    └─Softplus: 3-27                         [2, 2, 5313]              --\n",
       "│    └─Sequential: 2-9                             [2, 2, 1643]              --\n",
       "│    │    └─Linear: 3-28                           [2, 2, 1643]              5,048,939\n",
       "│    │    └─Softplus: 3-29                         [2, 2, 1643]              --\n",
       "====================================================================================================\n",
       "Total params: 251,221,292\n",
       "Trainable params: 251,221,292\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 2.55\n",
       "====================================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 26499.94\n",
       "Params size (MB): 1004.84\n",
       "Estimated Total Size (MB): 27511.07\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MPRA_exp.utils import *\n",
    "from enformer_pytorch import Enformer\n",
    "\n",
    "pretrained_model_path = 'pretrained_models/enformer/'\n",
    "model = Enformer.from_pretrained(pretrained_model_name_or_path=pretrained_model_path, target_length=2).cuda()\n",
    "model.eval()\n",
    "\n",
    "summary(model, (2, 196_608, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e62da015c2b8e1460a389c60847c46fcac689812463b880d1463e5f1a16b0d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
