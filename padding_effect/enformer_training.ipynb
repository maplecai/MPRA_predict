{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb_ShvB9E8yM"
      },
      "source": [
        "Copyright 2021 DeepMind Technologies Limited\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXQjDxgdwUmW"
      },
      "source": [
        "This colab showcases training of the Enformer model published in\n",
        "\n",
        "**\"Effective gene expression prediction from sequence by integrating long-range interactions\"**\n",
        "\n",
        "Å½iga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, David R. Kelley\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AVkKjy3bh_A"
      },
      "source": [
        "## Steps\n",
        "\n",
        "- Setup tf.data.Dataset by directly accessing the Basenji2 data on GCS: `gs://basenji_barnyard/data`\n",
        "- Train the model for a few steps, alternating training on human and mouse data batches\n",
        "- Evaluate the model on human and mouse genomes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM_PMOT-2Xhi"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqR7ol3rxrtM"
      },
      "source": [
        "**Start the colab kernel with GPU**: Runtime -> Change runtime type -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhjR7StI1tZn"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiDFm-a41tKW",
        "outputId": "8b889c6e-f113-4664-f2c9-91110808ad92"
      },
      "outputs": [],
      "source": [
        "# !pip install dm-sonnet tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CokqDsb-fxme"
      },
      "outputs": [],
      "source": [
        "# # Get enformer source code\n",
        "# !wget -q https://raw.githubusercontent.com/deepmind/deepmind-research/master/enformer/attention_module.py\n",
        "# !wget -q https://raw.githubusercontent.com/deepmind/deepmind-research/master/enformer/enformer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmffZS_306eb"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTGOLrbZxNHK",
        "outputId": "f58b5c21-0764-4003-c794-aa89e5d336cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-10 14:13:25.145811: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-10 14:13:25.209327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1733811205.236248   42076 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1733811205.244722   42076 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-10 14:13:25.314414: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n",
            "True\n",
            "WARNING:tensorflow:From /tmp/ipykernel_42076/3518036306.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1733811206.678277   42076 gpu_device.cc:2022] Created device /device:GPU:0 with 22280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:06:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.is_built_with_cuda())\n",
        "print(tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.2\n",
            "12.1\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S9ywsUmT05C1"
      },
      "outputs": [],
      "source": [
        "import sonnet as snt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "import enformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xx--Nco09fN"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MEb8OZli2Nbu"
      },
      "outputs": [],
      "source": [
        "# @title `get_targets(organism)`\n",
        "def get_targets(organism):\n",
        "  # targets_txt = f'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_{organism}.txt'\n",
        "  targets_file = f'/home/shared/enformer_data/{organism}/targets.txt'\n",
        "  return pd.read_csv(targets_file, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2BuZ2gmUbpXZ"
      },
      "outputs": [],
      "source": [
        "# @title `get_dataset(organism, subset, num_threads=8)`\n",
        "import glob\n",
        "import json\n",
        "import functools\n",
        "\n",
        "\n",
        "def organism_path(organism):\n",
        "  # return os.path.join('gs://basenji_barnyard/data', organism)\n",
        "  return os.path.join('/home/shared/enformer_data', organism) # my local path\n",
        "\n",
        "\n",
        "def get_dataset(organism, subset, num_threads=8):\n",
        "  metadata = get_metadata(organism)\n",
        "  dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n",
        "                                    compression_type='ZLIB',\n",
        "                                    num_parallel_reads=num_threads)\n",
        "  dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n",
        "                        num_parallel_calls=num_threads)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def get_metadata(organism):\n",
        "  # Keys:\n",
        "  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
        "  # pool_width, crop_bp, target_length\n",
        "  path = os.path.join(organism_path(organism), 'statistics.json')\n",
        "  with tf.io.gfile.GFile(path, 'r') as f:\n",
        "    return json.load(f)\n",
        "\n",
        "\n",
        "def tfrecord_files(organism, subset):\n",
        "  # Sort the values by int(*).\n",
        "  return sorted(tf.io.gfile.glob(os.path.join(\n",
        "      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n",
        "  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
        "\n",
        "\n",
        "def deserialize(serialized_example, metadata):\n",
        "  \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
        "  feature_map = {\n",
        "      'sequence': tf.io.FixedLenFeature([], tf.string),\n",
        "      'target': tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "  example = tf.io.parse_example(serialized_example, feature_map)\n",
        "  sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
        "  sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n",
        "  sequence = tf.cast(sequence, tf.float32)\n",
        "\n",
        "  target = tf.io.decode_raw(example['target'], tf.float16)\n",
        "  target = tf.reshape(target,\n",
        "                      (metadata['target_length'], metadata['num_targets']))\n",
        "  target = tf.cast(target, tf.float32)\n",
        "\n",
        "  return {'sequence': sequence,\n",
        "          'target': target}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzGRXfwV4tYH"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "M_vr1mbl3jbD",
        "outputId": "2de351ed-f43e-4469-a681-2a437d97c946"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>genome</th>\n",
              "      <th>identifier</th>\n",
              "      <th>file</th>\n",
              "      <th>clip</th>\n",
              "      <th>scale</th>\n",
              "      <th>sum_stat</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ENCFF833POA</td>\n",
              "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>mean</td>\n",
              "      <td>DNASE:cerebellum male adult (27 years) and mal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ENCFF110QGM</td>\n",
              "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>mean</td>\n",
              "      <td>DNASE:frontal cortex male adult (27 years) and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>ENCFF880MKD</td>\n",
              "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>mean</td>\n",
              "      <td>DNASE:chorion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>ENCFF463ZLQ</td>\n",
              "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>mean</td>\n",
              "      <td>DNASE:Ishikawa treated with 0.02% dimethyl sul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>ENCFF890OGQ</td>\n",
              "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>mean</td>\n",
              "      <td>DNASE:GM03348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  genome   identifier  \\\n",
              "0      0       0  ENCFF833POA   \n",
              "1      1       0  ENCFF110QGM   \n",
              "2      2       0  ENCFF880MKD   \n",
              "3      3       0  ENCFF463ZLQ   \n",
              "4      4       0  ENCFF890OGQ   \n",
              "\n",
              "                                                file  clip  scale sum_stat  \\\n",
              "0  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
              "1  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
              "2  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
              "3  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
              "4  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
              "\n",
              "                                         description  \n",
              "0  DNASE:cerebellum male adult (27 years) and mal...  \n",
              "1  DNASE:frontal cortex male adult (27 years) and...  \n",
              "2                                      DNASE:chorion  \n",
              "3  DNASE:Ishikawa treated with 0.02% dimethyl sul...  \n",
              "4                                      DNASE:GM03348  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_targets_human = get_targets('human')\n",
        "df_targets_human.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YDSKttXI4hMT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1733811211.300885   42076 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:06:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "human_dataset = get_dataset('human', 'train').batch(1).repeat()\n",
        "# mouse_dataset = get_dataset('mouse', 'train').batch(1).repeat()\n",
        "# human_mouse_dataset = tf.data.Dataset.zip((human_dataset, mouse_dataset)).prefetch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sequence': (TensorShape([1, 131072, 4]), tf.float32), 'target': (TensorShape([1, 896, 5313]), tf.float32)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-10 14:13:32.300581: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
            "2024-12-10 14:13:32.303499: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:370] TFRecordDataset `buffer_size` is unspecified, default to 262144\n"
          ]
        }
      ],
      "source": [
        "# Example input\n",
        "it = iter(human_dataset)\n",
        "example = next(it)\n",
        "print({k: (v.shape, v.dtype) for k,v in example.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHHNHzFVbvTk"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0U3hLJaUdZkG"
      },
      "outputs": [],
      "source": [
        "def create_step_function(model, optimizer):\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(batch, head, optimizer_clip_norm_global=0.2):\n",
        "    with tf.GradientTape() as tape:\n",
        "      outputs = model(batch['sequence'], is_training=True)[head]\n",
        "      loss = tf.reduce_mean(\n",
        "          tf.keras.losses.poisson(batch['target'], outputs))\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply(gradients, model.trainable_variables)\n",
        "\n",
        "    return loss\n",
        "  return train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZXv5HU_242Ut"
      },
      "outputs": [],
      "source": [
        "learning_rate = tf.Variable(0., trainable=False, name='learning_rate')\n",
        "optimizer = snt.optimizers.Adam(learning_rate=learning_rate)\n",
        "num_warmup_steps = 5000\n",
        "target_learning_rate = 0.0005\n",
        "\n",
        "model = enformer.Enformer(channels=1536 // 4,  # Use 4x fewer channels to train faster.\n",
        "                          num_heads=8,\n",
        "                          num_transformer_layers=11,\n",
        "                          pooling_type='max')\n",
        "\n",
        "train_step = create_step_function(model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrbDaOMWcFUl",
        "outputId": "6a42f69c-3003-47f2-a8d2-1b94c52eb57e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'human_mouse_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 5\u001b[0m data_it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mhuman_mouse_dataset\u001b[49m)\n\u001b[1;32m      6\u001b[0m global_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'human_mouse_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "steps_per_epoch = 20\n",
        "num_epochs = 5\n",
        "\n",
        "data_it = iter(human_mouse_dataset)\n",
        "global_step = 0\n",
        "for epoch_i in range(num_epochs):\n",
        "  for i in tqdm(range(steps_per_epoch)):\n",
        "    global_step += 1\n",
        "\n",
        "    if global_step > 1:\n",
        "      learning_rate_frac = tf.math.minimum(\n",
        "          1.0, global_step / tf.math.maximum(1.0, num_warmup_steps))\n",
        "      learning_rate.assign(target_learning_rate * learning_rate_frac)\n",
        "\n",
        "    batch_human, batch_mouse = next(data_it)\n",
        "\n",
        "    loss_human = train_step(batch=batch_human, head='human')\n",
        "    loss_mouse = train_step(batch=batch_mouse, head='mouse')\n",
        "\n",
        "  # End of epoch.\n",
        "  print('')\n",
        "  print('loss_human', loss_human.numpy(),\n",
        "        'loss_mouse', loss_mouse.numpy(),\n",
        "        'learning_rate', optimizer.learning_rate.numpy()\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs0f0z0RcCfz"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "8c4lNQrHkXSC"
      },
      "outputs": [],
      "source": [
        "# @title `PearsonR` and `R2` metrics\n",
        "\n",
        "def _reduced_shape(shape, axis):\n",
        "  if axis is None:\n",
        "    return tf.TensorShape([])\n",
        "  return tf.TensorShape([d for i, d in enumerate(shape) if i not in axis])\n",
        "\n",
        "\n",
        "class CorrelationStats(tf.keras.metrics.Metric):\n",
        "  \"\"\"Contains shared code for PearsonR and R2.\"\"\"\n",
        "\n",
        "  def __init__(self, reduce_axis=None, name='pearsonr'):\n",
        "    \"\"\"Pearson correlation coefficient.\n",
        "\n",
        "    Args:\n",
        "      reduce_axis: Specifies over which axis to compute the correlation (say\n",
        "        (0, 1). If not specified, it will compute the correlation across the\n",
        "        whole tensor.\n",
        "      name: Metric name.\n",
        "    \"\"\"\n",
        "    super(CorrelationStats, self).__init__(name=name)\n",
        "    self._reduce_axis = reduce_axis\n",
        "    self._shape = None  # Specified in _initialize.\n",
        "\n",
        "  def _initialize(self, input_shape):\n",
        "    # Remaining dimensions after reducing over self._reduce_axis.\n",
        "    self._shape = _reduced_shape(input_shape, self._reduce_axis)\n",
        "\n",
        "    weight_kwargs = dict(shape=self._shape, initializer='zeros')\n",
        "    self._count = self.add_weight(name='count', **weight_kwargs)\n",
        "    self._product_sum = self.add_weight(name='product_sum', **weight_kwargs)\n",
        "    self._true_sum = self.add_weight(name='true_sum', **weight_kwargs)\n",
        "    self._true_squared_sum = self.add_weight(name='true_squared_sum',\n",
        "                                             **weight_kwargs)\n",
        "    self._pred_sum = self.add_weight(name='pred_sum', **weight_kwargs)\n",
        "    self._pred_squared_sum = self.add_weight(name='pred_squared_sum',\n",
        "                                             **weight_kwargs)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    \"\"\"Update the metric state.\n",
        "\n",
        "    Args:\n",
        "      y_true: Multi-dimensional float tensor [batch, ...] containing the ground\n",
        "        truth values.\n",
        "      y_pred: float tensor with the same shape as y_true containing predicted\n",
        "        values.\n",
        "      sample_weight: 1D tensor aligned with y_true batch dimension specifying\n",
        "        the weight of individual observations.\n",
        "    \"\"\"\n",
        "    if self._shape is None:\n",
        "      # Explicit initialization check.\n",
        "      self._initialize(y_true.shape)\n",
        "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
        "    y_true = tf.cast(y_true, 'float32')\n",
        "    y_pred = tf.cast(y_pred, 'float32')\n",
        "\n",
        "    self._product_sum.assign_add(\n",
        "        tf.reduce_sum(y_true * y_pred, axis=self._reduce_axis))\n",
        "\n",
        "    self._true_sum.assign_add(\n",
        "        tf.reduce_sum(y_true, axis=self._reduce_axis))\n",
        "\n",
        "    self._true_squared_sum.assign_add(\n",
        "        tf.reduce_sum(tf.math.square(y_true), axis=self._reduce_axis))\n",
        "\n",
        "    self._pred_sum.assign_add(\n",
        "        tf.reduce_sum(y_pred, axis=self._reduce_axis))\n",
        "\n",
        "    self._pred_squared_sum.assign_add(\n",
        "        tf.reduce_sum(tf.math.square(y_pred), axis=self._reduce_axis))\n",
        "\n",
        "    self._count.assign_add(\n",
        "        tf.reduce_sum(tf.ones_like(y_true), axis=self._reduce_axis))\n",
        "\n",
        "  def result(self):\n",
        "    raise NotImplementedError('Must be implemented in subclasses.')\n",
        "\n",
        "  def reset_states(self):\n",
        "    if self._shape is not None:\n",
        "      tf.keras.backend.batch_set_value([(v, np.zeros(self._shape))\n",
        "                                        for v in self.variables])\n",
        "\n",
        "\n",
        "class PearsonR(CorrelationStats):\n",
        "  \"\"\"Pearson correlation coefficient.\n",
        "\n",
        "  Computed as:\n",
        "  ((x - x_avg) * (y - y_avg) / sqrt(Var[x] * Var[y])\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, reduce_axis=(0,), name='pearsonr'):\n",
        "    \"\"\"Pearson correlation coefficient.\n",
        "\n",
        "    Args:\n",
        "      reduce_axis: Specifies over which axis to compute the correlation.\n",
        "      name: Metric name.\n",
        "    \"\"\"\n",
        "    super(PearsonR, self).__init__(reduce_axis=reduce_axis,\n",
        "                                   name=name)\n",
        "\n",
        "  def result(self):\n",
        "    true_mean = self._true_sum / self._count\n",
        "    pred_mean = self._pred_sum / self._count\n",
        "\n",
        "    covariance = (self._product_sum\n",
        "                  - true_mean * self._pred_sum\n",
        "                  - pred_mean * self._true_sum\n",
        "                  + self._count * true_mean * pred_mean)\n",
        "\n",
        "    true_var = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
        "    pred_var = self._pred_squared_sum - self._count * tf.math.square(pred_mean)\n",
        "    tp_var = tf.math.sqrt(true_var) * tf.math.sqrt(pred_var)\n",
        "    correlation = covariance / tp_var\n",
        "\n",
        "    return correlation\n",
        "\n",
        "\n",
        "class R2(CorrelationStats):\n",
        "  \"\"\"R-squared  (fraction of explained variance).\"\"\"\n",
        "\n",
        "  def __init__(self, reduce_axis=None, name='R2'):\n",
        "    \"\"\"R-squared metric.\n",
        "\n",
        "    Args:\n",
        "      reduce_axis: Specifies over which axis to compute the correlation.\n",
        "      name: Metric name.\n",
        "    \"\"\"\n",
        "    super(R2, self).__init__(reduce_axis=reduce_axis,\n",
        "                             name=name)\n",
        "\n",
        "  def result(self):\n",
        "    true_mean = self._true_sum / self._count\n",
        "    total = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
        "    residuals = (self._pred_squared_sum - 2 * self._product_sum\n",
        "                 + self._true_squared_sum)\n",
        "\n",
        "    return tf.ones_like(residuals) - residuals / total\n",
        "\n",
        "\n",
        "class MetricDict:\n",
        "  def __init__(self, metrics):\n",
        "    self._metrics = metrics\n",
        "\n",
        "  def update_state(self, y_true, y_pred):\n",
        "    for k, metric in self._metrics.items():\n",
        "      metric.update_state(y_true, y_pred)\n",
        "\n",
        "  def result(self):\n",
        "    return {k: metric.result() for k, metric in self._metrics.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x80gX9LrhBU-"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, head, max_steps=None):\n",
        "  metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
        "  @tf.function\n",
        "  def predict(x):\n",
        "    return model(x, is_training=False)[head]\n",
        "\n",
        "  for i, batch in tqdm(enumerate(dataset)):\n",
        "    if max_steps is not None and i > max_steps:\n",
        "      break\n",
        "    metric.update_state(batch['target'], predict(batch['sequence']))\n",
        "\n",
        "  return metric.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = enformer.Enformer(channels=1536 // 4,  # Use 4x fewer channels to train faster.\n",
        "                          num_heads=8,\n",
        "                          num_transformer_layers=11,\n",
        "                          pooling_type='max')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57fNitK9hzwd",
        "outputId": "947aaadb-dad2-4a00-ddac-d765f65d782f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"/tmp/ipykernel_42076/3450058308.py\", line 5, in predict  *\n        return model(x, is_training=False)[head]\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/utils.py\", line 85, in _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/base.py\", line 262, in wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    File \"/home/hxcai/cell_type_specific_CRE/MPRA_predict/notebooks/pretrained_models/enformer.py\", line 175, in __call__  *\n        trunk_embedding = self.trunk(inputs, is_training=is_training)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/utils.py\", line 85, in _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/base.py\", line 262, in wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    File \"/home/hxcai/cell_type_specific_CRE/MPRA_predict/notebooks/pretrained_models/enformer.py\", line 231, in __call__  *\n        outputs = mod(outputs, **kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/utils.py\", line 85, in _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/base.py\", line 262, in wrap_with_name_scope  *\n        return method(*args, **kwargs)\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf____call__() missing 1 required positional argument: 'is_training'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_human \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m({k: v\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics_human\u001b[38;5;241m.\u001b[39mitems()})\n",
            "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataset, head, max_steps)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m max_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m max_steps:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m   metric\u001b[38;5;241m.\u001b[39mupdate_state(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msequence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mresult()\n",
            "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filer3s0t70z.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope)[ag__\u001b[38;5;241m.\u001b[39mld(head)]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_file1x_sxfg1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___decorate_unbound_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(decorator_fn), (ag__\u001b[38;5;241m.\u001b[39mld(bound_method), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(args), ag__\u001b[38;5;241m.\u001b[39mld(kwargs)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileh3zr56d7.py:47\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrap_with_name_scope\u001b[0;34m(method, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(method), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filekh3qbms6.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, inputs, is_training)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m trunk_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_training\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_file1x_sxfg1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___decorate_unbound_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(decorator_fn), (ag__\u001b[38;5;241m.\u001b[39mld(bound_method), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(args), ag__\u001b[38;5;241m.\u001b[39mld(kwargs)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileh3zr56d7.py:47\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrap_with_name_scope\u001b[0;34m(method, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(method), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileg0umdxpt.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, inputs, is_training, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m _ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m mod \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmod\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(_, mod)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileg0umdxpt.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m outputs\n\u001b[1;32m     36\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(mod), (ag__\u001b[38;5;241m.\u001b[39mld(outputs),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccepts_is_training\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileg0umdxpt.py:36\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.loop_body.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m outputs\n\u001b[0;32m---> 36\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_file1x_sxfg1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___decorate_unbound_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(decorator_fn), (ag__\u001b[38;5;241m.\u001b[39mld(bound_method), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(args), ag__\u001b[38;5;241m.\u001b[39mld(kwargs)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileh3zr56d7.py:47\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrap_with_name_scope\u001b[0;34m(method, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(method), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_42076/3450058308.py\", line 5, in predict  *\n        return model(x, is_training=False)[head]\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/utils.py\", line 85, in _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/base.py\", line 262, in wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    File \"/home/hxcai/cell_type_specific_CRE/MPRA_predict/notebooks/pretrained_models/enformer.py\", line 175, in __call__  *\n        trunk_embedding = self.trunk(inputs, is_training=is_training)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/utils.py\", line 85, in _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/base.py\", line 262, in wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    File \"/home/hxcai/cell_type_specific_CRE/MPRA_predict/notebooks/pretrained_models/enformer.py\", line 231, in __call__  *\n        outputs = mod(outputs, **kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/utils.py\", line 85, in _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    File \"/home/hxcai/anaconda3/envs/torch/lib/python3.10/site-packages/sonnet/src/base.py\", line 262, in wrap_with_name_scope  *\n        return method(*args, **kwargs)\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf____call__() missing 1 required positional argument: 'is_training'\n"
          ]
        }
      ],
      "source": [
        "metrics_human = evaluate_model(model,\n",
        "                               dataset=get_dataset('human', 'valid').batch(1).prefetch(2),\n",
        "                               head='human',\n",
        "                               max_steps=100)\n",
        "print('')\n",
        "print({k: v.numpy().mean() for k, v in metrics_human.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY_wj95xiDtE",
        "outputId": "fea839f7-b6c9-46ed-aece-c56b02e9ea16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "101it [00:21,  6.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "{'PearsonR': 0.005183698}\n"
          ]
        }
      ],
      "source": [
        "# metrics_mouse = evaluate_model(model,\n",
        "#                                dataset=get_dataset('mouse', 'valid').batch(1).prefetch(2),\n",
        "#                                head='mouse',\n",
        "#                                max_steps=100)\n",
        "# print('')\n",
        "# print({k: v.numpy().mean() for k, v in metrics_mouse.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k1yaJrNCgvw"
      },
      "source": [
        "# Restore Checkpoint\n",
        "\n",
        "Note: For the TF-Hub Enformer model, the required input sequence length is 393,216 which actually gets cropped within the model to 196,608. The open source module does not internally crop the sequence. Therefore, the code below crops the central `196,608 bp` of the longer sequence to reproduce the output of the TF hub from the reloaded checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2cGdH8EGfn"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "EXTENDED_SEQ_LENGTH = 393_216\n",
        "SEQ_LENGTH = 196_608\n",
        "inputs = np.array(np.random.random((1, EXTENDED_SEQ_LENGTH, 4)), dtype=np.float32)\n",
        "inputs_cropped = enformer.TargetLengthCrop1D(SEQ_LENGTH)(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdf35itsCjEY"
      },
      "outputs": [],
      "source": [
        "checkpoint_gs_path = 'gs://dm-enformer/models/enformer/sonnet_weights/*'\n",
        "checkpoint_path = '/tmp/enformer_checkpoint'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2P4IHqswLul",
        "outputId": "180abe21-ba00-4031-d9d7-2326f1f742f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â/tmp/enformer_checkpointâ: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /tmp/enformer_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTL8EISGCujC",
        "outputId": "2b743b9b-480d-44dc-b08e-82d2bc089a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://dm-enformer/models/enformer/sonnet_weights/checkpoint\n",
            "gs://dm-enformer/models/enformer/sonnet_weights/enformer-fine-tuned-human-1.data-00000-of-00001\n",
            "gs://dm-enformer/models/enformer/sonnet_weights/enformer-fine-tuned-human-1.index\n"
          ]
        }
      ],
      "source": [
        "# Copy checkpoints from GCS to temporary directory.\n",
        "# This will take a while as the checkpoint is ~ 1GB.\n",
        "for file_path in tf.io.gfile.glob(checkpoint_gs_path):\n",
        "  print(file_path)\n",
        "  file_name = os.path.basename(file_path)\n",
        "  tf.io.gfile.copy(file_path, f'{checkpoint_path}/{file_name}', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VSeTx0sCvcw",
        "outputId": "b52d7570-c355-4068-b932-3796b56e5586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 959M\n",
            "-rw-r--r-- 1 root root  111 May 25 10:58 checkpoint\n",
            "-rw-r--r-- 1 root root 959M May 25 10:59 enformer-fine-tuned-human-1.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 5.7K May 25 10:59 enformer-fine-tuned-human-1.index\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /tmp/enformer_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Y2GgRED3aI"
      },
      "outputs": [],
      "source": [
        "enformer_model = enformer.Enformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFyIiGyiD5yh"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.train.Checkpoint(module=enformer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuyspnpOD9kA",
        "outputId": "3b495138-be27-4459-af82-c5da2af5bd2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/enformer_checkpoint/enformer-fine-tuned-human-1\n"
          ]
        }
      ],
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_path)\n",
        "print(latest)\n",
        "status = checkpoint.restore(latest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKkVOTyKEABJ"
      },
      "outputs": [],
      "source": [
        "# Using `is_training=False` to match TF-hub predict_on_batch function.\n",
        "restored_predictions = enformer_model(inputs_cropped, is_training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX650jqCEQdv"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "enformer_tf_hub_model = hub.load(\"https://tfhub.dev/deepmind/enformer/1\").model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiOTFTSdE5H1"
      },
      "outputs": [],
      "source": [
        "hub_predictions = enformer_tf_hub_model.predict_on_batch(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYrWgfaGFbpL",
        "outputId": "cb9d3ad0-ee14-46ac-b188-a4b6a697a159"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.allclose(hub_predictions['human'], restored_predictions['human'], atol=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wEOUMeNzK8q"
      },
      "outputs": [],
      "source": [
        "# Can run with 'is_training=True' but note that this will\n",
        "# change the predictions as the batch statistics will be updated\n",
        "# and the outputs will likley not match the TF-hub model.\n",
        "# enformer(inputs_cropped, is_training=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyVHRPAN5w6J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "enformer-training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
