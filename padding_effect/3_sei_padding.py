import os
import sys
import torch
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader, Subset

sys.path.append("..")
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from MPRA_predict import models, datasets, metrics, utils
from MPRA_predict.utils import *


def get_pred(model, test_data_loader, device='cuda'):
    model = model.to(device)
    y_pred = []
    model.eval()
    with torch.no_grad():
        for i, batch in enumerate(tqdm(test_data_loader)):
            if isinstance(batch, (list, tuple)):
                x = batch[0]
            elif isinstance(batch, dict):
                x = batch['seq']
            else:
                x = batch
            x = x.to(device)
            output = model(x)
            y_pred.append(output.detach().cpu().numpy())
            del batch, x, output  # 清理内存
    y_pred = np.concatenate(y_pred, axis=0)
    torch.cuda.empty_cache()
    return y_pred




# def get_pred_total(model, dataset, device, output_path):
#     test_data_loader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)
#     pred = get_pred(model, test_data_loader, device)
#     np.save(output_path, pred)
#     return



# # split to many parts, predict and save, in order to save memory
# def get_pred_split(model, dataset, device, output_path, num_splits):

#     split_size = len(dataset) // num_splits  # num_splits是你要分割的部分数
#     # 分割数据集
#     for i in range(num_splits):
#         start_idx = i * split_size
#         end_idx = (i + 1) * split_size if i != num_splits - 1 else len(dataset)

#         subset = Subset(dataset, range(start_idx, end_idx))
#         subloader = DataLoader(subset, batch_size=4, shuffle=False, num_workers=0)
#         y_pred = get_pred(model, subloader, device)
#         np.save(f'{output_path}_{i}.npy', np.array(y_pred))
#     return




if __name__ == '__main__':

    set_seed(0)
    device = f'cuda:0'
    model_path = f'pretrained_models/Sei/sei.pth'
    data_path = f'data/Sei/sei_chr8_dataset.csv'

    model = models.Sei()
    model_state_dict = torch.load(model_path)
    model_state_dict = {k.replace('module.model.', ''): v for k, v in model_state_dict.items()}
    model.load_state_dict(model_state_dict, strict=False)
    
    for cropped_length in [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]:
        output_path = f'padding_effect/outputs/Sei_pred_crop_{cropped_length}_repeat.npy'

        if os.path.exists(output_path):
            print(f'already exists {output_path}, skip')
            continue
        print(f'predicting {output_path}')

        dataset = datasets.SeqDataset(
            data_path=data_path,
            seq_column='seq', 
            crop=True,
            crop_method='center',
            cropped_length=cropped_length,
            padding=True,
            padded_length=4096,

            # # N
            # padding_method='N',
            # # zero
            # padding_method='N',
            # N_fill_value=0,
            # # random
            # padding_method='random',
            # genome
            # padding_method='genome',
            # genome=Fasta('data/genome/hg38.fa')
            # repeat
            padding_method='repeat',
        )
        
        test_data_loader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=1)
        pred = get_pred(model, test_data_loader, device)
        np.save(output_path, pred)
